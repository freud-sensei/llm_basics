{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6AmrqxAplIZ3vNb57nVgx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. 딥러닝과 언어 모델링"],"metadata":{"id":"QafxV0vqSMBo"}},{"cell_type":"markdown","source":["* **LLM**: **다음에 올 단어를 예측**하며 문장을 하나씩 만들어 나가는 방식으로 텍스트를 생성하는 딥러닝 모델\n","\n","* 딥러닝 모델은 데이터의 특징을 스스로 추출\n","\n","* **임베딩**: 데이터의 의미와 특징을 포착해 숫자로 표현한 것\n","    * 데이터 사이 거리를 계산해 데이터 간 유사도 확인 가능\n","    * **단어 임베딩**: 단어를 임베딩으로 변환한 것 (e.g., word2vec)"],"metadata":{"id":"if4Ct58PSRr8"}},{"cell_type":"markdown","source":["* **전이 학습(transfer learning)**: 하나의 문제를 해결하는 과정에서 얻은 지식과 정보를, 다른 문제를 풀 때 사용하는 방식\n","    * **사전 학습**: 대량의 데이터로 모델을 학습\n","    * **fine-tuning**: 다운스트림 과제를 해결하기 위한 데이터로 추가 학습\n","    * 언어 모델링(다음 단어 맞추기)으로 사전 학습을 수행하고 fine-tuning했을 때, 다운스트림 과제(e.g., 문장 분류)에서 모델의 성능이 더 높음\n"],"metadata":{"id":"yjFWf4TnTZUh"}},{"cell_type":"markdown","source":["# 2. 언어 모델이 챗GPT가 되기까지"],"metadata":{"id":"tuZ9OVX7VwRs"}},{"cell_type":"markdown","source":["* RNN(순환 신경망)\n","    * 시퀀스를 순차적으로 처리하며, **hidden state에 지금까지의 입력 텍스트의 맥락을 압축**\n","    * 다음 데이터를 예측할 때, 계산된 hidden state와 현재 입력 단어만 필요하므로 다음 단어를 빠르게 생성 가능\n","    * 단점: 먼저 입력한 단어의 의미가 점차 희석되어, 입력이 길어질수록 성능이 떨어짐\n","    * e.g., '검은 고양이가 밥을 먹고 물을'을 맥락 압축 -> 이를 통해 '마신다' 예측\n","\n","* 트랜스포머 內 Attention 연산\n","    * 순차적인 처리 방식 대신, 시퀀스의 맥락을 모두 참조\n","    * 하나의 잠재 상태로 맥락을 압축하는 대신, **맥락 데이터를 모두 활용해** 다음 단어를 예측\n","    * RNN에 비해 높은 성능, but 메모리 사용량 증가\n","    * e.g., '마신다'를 예측할 때, '검은', '고양이가', ..., '물을'과의 관계를 모두 계산\n","\n"],"metadata":{"id":"_Y2ip9BJV6KY"}},{"cell_type":"markdown","source":["* ChatGPT의 등장\n","    * 정렬: LLM이 생성하는 답변을 사용자의 요청 의도에 맞추는 것\n","    * **supervised fine-tuning**: 언어 모델링으로 사전 학습한 언어 모델을 instruction dataset으로 추가 학습하는 것\n","        * instruction dataset: 사용자의 요청/지시사항과 이에 대한 적절한 응답을 정리한 데이터셋\n","    * **RLHF** (reinforced learning from human feedback): 2가지 답변 중 사용자가 선호하는 답변을 구축한 데이터셋을 통해, LLM이 더 높을 점수를 받을 수 있도록 학습하는 강화 학습 모델"],"metadata":{"id":"lqKDFWydYGLu"}},{"cell_type":"markdown","source":["# 3. LLM 애플리케이션"],"metadata":{"id":"7ixZwiosY2Bv"}},{"cell_type":"markdown","source":["* sLLM: 작고 효율적인 LLM 모델 만들기\n","    * 오픈소스 LLM을 추가 학습하여, 모델 크기가 작으면서도 특정 도메인 데이터나 작업에서 높은 성능을 보이는 모델을 생성 가능\n","* 효율적인 학습과 추론을 위한 기술\n","    * 적은 GPU 자원으로도 LLM 활용하기\n","    * 양자화: 모델 파라미터를 더 적은 비트로 표현\n","    * LoRA (Low Rank Adaptation): 모델 전체가 아닌 일부만 학습\n","* RAG(Retrieval Augmented Generation): 검색 증강 생성\n","    * 환각 현상: LLM이 부정확한 정보를 생성하는 현상\n","    * RAG는 프롬프트에 LLM이 답변할 때 필요한 정보를 미리 추가하여, 환각 현상을 줄임"],"metadata":{"id":"uY7mb95qY4EK"}},{"cell_type":"markdown","source":["# 4. LLM의 미래: 인식과 행동의 확장\n","* 멀티모달 LLM: 이미지, 비디오, 오디오 등 다양한 형식의 데이터 입출력 가능\n","* 에이전트: LLM을 스스로 판단하고 행동하는 에이전트의 두뇌로 사용"],"metadata":{"id":"HJLjM4ivat3W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnJv-P_NR-mq"},"outputs":[],"source":[]}]}